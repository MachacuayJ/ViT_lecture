{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
      ],
      "metadata": {
        "id": "RGxXhIuCentg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1WtqzFKgO6qSpBGNbbjGMYgWjtprREZfx'>"
      ],
      "metadata": {
        "id": "XEIfhlcEhcRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1wQxQ7BgaLvrRmlFIGU0ymGJ_AmGqYVFM'>"
      ],
      "metadata": {
        "id": "gAEXu6GMmTrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "6giDEL1lcHJg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layers"
      ],
      "metadata": {
        "id": "YbiWcBwAcBzT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Preprocessing"
      ],
      "metadata": {
        "id": "86mZqJIOcPr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize and resize the images."
      ],
      "metadata": {
        "id": "TD8Vg7EPePTa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mi2Z1-z8cBU7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Patching"
      ],
      "metadata": {
        "id": "6oJO-HXscUYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the patches from the images."
      ],
      "metadata": {
        "id": "0yrw6buiedHT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4WlZ9rZBcUjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding Patches"
      ],
      "metadata": {
        "id": "Z6AU2Nkjcgrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the positional embeddings and encode them with the linear projections of the flattened patches."
      ],
      "metadata": {
        "id": "Je6ZAAvRemlx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rgb6BQjicg_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Transformer Encoder*"
      ],
      "metadata": {
        "id": "1aQCBq_tcnFY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the transformer encoder. This should follow the following architecture:\n",
        "\n"
      ],
      "metadata": {
        "id": "2Dm8RXXdfNEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1tWq5cjpQUPGHt_MLQRoysmlaQzoEKJpz'>"
      ],
      "metadata": {
        "id": "cOWJBIk3mEo8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Quma1OAocnqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {
        "id": "vZFKBjNpczXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "CE7i9JPmdo1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the CIFAR100 dataset."
      ],
      "metadata": {
        "id": "8q0ALt17ktw0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CMDWkig6doaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build model"
      ],
      "metadata": {
        "id": "dYoi4IsUdqMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the ViT. Do not forget to adapt the normalize layer to the x_train features with the \"adapt\" method of the normalization layer."
      ],
      "metadata": {
        "id": "6iwTJV0dkxTY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CJixXfkkcv0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vp-msf0iqPtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model."
      ],
      "metadata": {
        "id": "mNZ6qX0Uk2_B"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XCgUZpcek3P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "jEIYhhVedsPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the ViT with the CIFAR100 data."
      ],
      "metadata": {
        "id": "sjJ1xfVJk5cr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cHI9CIxNdr8K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}